{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this block is used for copying/moving files\n",
    "import os\n",
    "import shutil\n",
    "import time\n",
    "#shutil.copyfile('src', 'dst')\n",
    "#shutil.move\n",
    "\n",
    "# we want to ensure we are in the correct conda environment\n",
    "import sys\n",
    "sys.executable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# provides ability to reload modules (wihtout leaving jupyter) if changes are made\n",
    "#import importlib\n",
    "#importlib.reload(scd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup as bs\n",
    "# import regular expressions\n",
    "import re \n",
    "\n",
    "from IPython.core.display import HTML\n",
    "css = open('style-table.css').read() + open('style-notebook.css').read()\n",
    "HTML('<style>{}</style>'.format(css))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cornavirus section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is a custom python module with dictionaries of states and countries; \n",
    "# it also contains three functions repair_dict, reverse_dict, and custom_list\n",
    "import state_country_dicts as scd\n",
    "\n",
    "# get current date for use in creating filenames with embedded 'day'. \n",
    "# convert datetime object to string\n",
    "import datetime as dt\n",
    "today  = dt.date.today()\n",
    "day = today.strftime('%Y-%m-%d')\n",
    "day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print ('If using Binder enter a timezone difference from UTC')\n",
    "timezone = input(' Enter a number between 12 and -12:')\n",
    "print(timezone)\n",
    "if timezone:\n",
    "    timezone = int(timezone)\n",
    "    v = scd.tz_dict[timezone]\n",
    "    t = pd.Timestamp.today(v)\n",
    "    print (t)\n",
    "    day = t.date().strftime('%Y-%m-%d')\n",
    "day"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Moves all files from covid_data_update to covid_data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure helper files used in past have been removed\n",
    "!rm -f covid_data/covid_text covid_data/flist_of_covid_png covid_data/temp.xlsx\n",
    "!rm -f covid_text flist_of_covid_png temp.xlsx\n",
    "\n",
    "!mkdir covid_data_update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# House keeping covid_data_update folder\n",
    "# preparing the move of all files from covid_data_update to covid_data \n",
    "# so that we are left with an empty covid_date_update folder\n",
    "file_names = []\n",
    "source_dir = 'covid_data_update'\n",
    "target_dir = 'covid_data'\n",
    "print(\"covid_data_update directory contents:\") \n",
    "file_names = os.listdir(source_dir)\n",
    "print (file_names)\n",
    "if file_names == []:\n",
    "    print ('Directory is empty so no files available to move')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The below will move and archive all files in covid_data_update to covid_data\n",
    "\n",
    "# Move contents of source ('covid_data_update')to target ('covid_data')\n",
    "for file_name in file_names:\n",
    "    try:\n",
    "        shutil.move(os.path.join(source_dir, file_name), target_dir)\n",
    "    except:\n",
    "        print(f'{file_name} already exists in target dir')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_up (number_str):\n",
    "    '''This is a clean up routine so that only numeric characters remain'''\n",
    "    number_str = number_str.replace(',', '').replace('null','0').rstrip(']').lstrip(\"'\")\n",
    "    return int(number_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom state dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creates a custom state dict\n",
    "s_string = input('Enter state codes seperated by a space:') or 'ca ny il'\n",
    "print()\n",
    "\n",
    "slist = scd.custom_list (s_string)\n",
    "state_dict = {key: value for key, value in scd.all_states.items() if value in slist}\n",
    "state_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add state and world population data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataframes\n",
    "all_state_pop = pd.read_csv('state_pop.csv').iloc[:,1:3].set_index('Code')\n",
    "all_state_pop.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataframes\n",
    "world_pop = pd.read_csv('world_pop.csv').iloc[:,0:2].set_index('country')\n",
    "temp = (world_pop.population/1000000).round(2)\n",
    "world_pop['pop_millions'] = temp\n",
    "world_pop.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### State Scraping section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The start dates for U.S.states and for countries are different so must be accounted for\n",
    "st_start = pd.Timestamp('2020/3/13')\n",
    "c_start = pd.Timestamp('2020/2/16')\n",
    "\n",
    "# set end date to yesterday\n",
    "\n",
    "#day == pd.Timestamp.today().strftime('%Y-%m-%d')\n",
    "end = pd.Timestamp.today() - pd.Timedelta(days=1)\n",
    "print(f'End date is set to yesterday: {end}')\n",
    "    \n",
    "# set the index to the appropriate date range for states and countries\n",
    "st_index = pd.date_range(st_start, end)\n",
    "c_index = pd.date_range(c_start, end)\n",
    "len(st_index)\n",
    "len(c_index)\n",
    "\n",
    "# list comprehension to extract just the state initials from the dict\n",
    "st_list = list(state_dict.values())\n",
    "\n",
    "# create an empty pandas df with column headers from state_dict\n",
    "state = pd.DataFrame(columns = st_list,index=st_index)\n",
    "state.sort_index(ascending = False).head()\n",
    "state.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_url='https://www.worldometers.info/coronavirus/usa/'\n",
    "# Here the keys are the state names and the values are the 2-letter abbreviation\n",
    "for key, value in state_dict.items():\n",
    "    url = state_url+key\n",
    "\n",
    "    # scrape web page for state info and assign to soup\n",
    "    response = requests.get(url)\n",
    "    #response.status_code\n",
    "    page = response.text\n",
    "    soup = bs(page)\n",
    "    \n",
    "    # Find block of text/data near 'graph-cases-daily' \n",
    "    re_graph = re.compile('graph-cases')\n",
    "    try:\n",
    "        data = soup.find(text=re_graph).parent\n",
    "    except:\n",
    "        print(f'Unable to find {url}')\n",
    "        print()\n",
    "        break\n",
    "    \n",
    "\n",
    "    # Regex to pull out data chunk out of the larger soup like data\n",
    "    myregex = re.compile (r'data:.*\\]')\n",
    "    mo = myregex.search(str(data))\n",
    "\n",
    "    #mo.group() is a string so easy to get rid of the first entry\n",
    "    #state_previous_cases is a list of daily new coronavirus cases\n",
    "    state_previous_cases = mo.group().split(',')[1:]\n",
    "    len(state_previous_cases)\n",
    "    \n",
    "    # ensure match between length of the empty df and the new list\n",
    "    if len(st_index)!= len(state_previous_cases):\n",
    "        print (len(st_index))\n",
    "        print (len(state_previous_cases))\n",
    "        state_previous_cases = state_previous_cases[:-1]\n",
    "        print (len(state_previous_cases))\n",
    "    \n",
    "    # merge states into the existing df and apply the function clean_up to convert strings to ints\n",
    "    # state[value] where value is the 2-letter abreviation\n",
    "    state[value] = state_previous_cases\n",
    "    state[value] = state[value].fillna(0).apply(clean_up)\n",
    "    \n",
    "    time.sleep(2)\n",
    "state.sort_index(ascending = False).head()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create df of new_cases/million population\n",
    "cols = state.columns.to_list()\n",
    "print(cols)\n",
    "\n",
    "# Extract just the poopulations for the states of interest\n",
    "pop_series = all_state_pop.loc[cols].pop_millions\n",
    "pop_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_cases_by_million = (state/pop_series).round()\n",
    "state_cases_by_million.tail(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot 7-day moving averge per million population\n",
    "plt.close('all')\n",
    "fig,ax = plt.subplots(1,1,figsize=(18,8))\n",
    "roll_data_all = state_cases_by_million.rolling(window=7).mean()\n",
    "roll_data_all.plot(ax=ax, linewidth=3);\n",
    "plt.title('US-Seven-day rolling averges per million population',fontsize=20);\n",
    "#plt.savefig(f'./covid_data_update/us_rolling_avg_per_million_{day}.png');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list2string(l): \n",
    "    ''' This creates a a short string of state/country names \n",
    "    used during file save\n",
    "    '''\n",
    "    str1 = \"_\" \n",
    "    # return string  \n",
    "    return (str1.join(l))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Allows user to select state for rolling average \n",
    "s_available = list(state.columns)\n",
    "print(f'States available: {s_available}')\n",
    "print()\n",
    "\n",
    "snames = (list2string(s_available))\n",
    "\n",
    "select_state = input('Choose state for rolling averge:')or s_available[0]\n",
    "select_state = select_state.upper()\n",
    "\n",
    "if select_state not in s_available:\n",
    "    select_state = s_available[0]\n",
    "\n",
    "# Plot Daily New Cases and 7-day moving averge\n",
    "fig,ax = plt.subplots(1,1,figsize=(18,8))\n",
    "roll_data = state.loc[:,[select_state]].rolling(window=7).mean()\n",
    "\n",
    "roll_data.plot(ax=ax, linewidth=3, color='r')\n",
    "state.plot(kind='area',alpha=.4,ax=ax,stacked=False);\n",
    "plt.title('Daily New Cases and 7-day moving average in RED', fontsize=20) \n",
    "\n",
    "#ax.set_title('Daily New Cases and 7-day moving average in RED', fontsize=20) \n",
    "plt.savefig(f'./covid_data_update/us_{day}.png');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot 7-day moving averge\n",
    "plt.close('all')\n",
    "fig,ax = plt.subplots(1,1,figsize=(18,8))\n",
    "roll_data_all = state.rolling(window=7).mean()\n",
    "roll_data_all.plot(ax=ax, linewidth=3);\n",
    "plt.title('US-Seven-day rolling averges',fontsize=20)\n",
    "plt.savefig(f'./covid_data_update/us_rolling_avg_{day}.png');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Last 60 Days\n",
    "plt.close('all')\n",
    "# Select last 60 days only\n",
    "state_last60 = state.tail(60)\n",
    "\n",
    "roll_data = state_last60.loc[:,[select_state]].rolling(window=7).mean()\n",
    "fig,ax = plt.subplots(1,1,figsize=(16,8))\n",
    "roll_data.plot(ax=ax, linewidth=3, color='r')\n",
    "state_last60.plot(kind='area',alpha=.4,ax=ax,stacked=False);\n",
    "\n",
    "plt.title('Daily New Cases in US - Last 60 Days',fontsize=20)\n",
    "plt.savefig(f'./covid_data_update/us_{snames}_last_60_days_{day}.png');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot last 90 days\n",
    "plt.close('all')\n",
    "# Select last 90 days only\n",
    "state_last90 = state.tail(90)\n",
    "\n",
    "roll_data = state_last90.loc[:,[select_state]].rolling(window=7).mean()\n",
    "fig,ax = plt.subplots(1,1,figsize=(16,8))\n",
    "roll_data.plot(ax=ax, linewidth=3, color='r')\n",
    "state_last90.plot(kind='area',alpha=.2,ax=ax,stacked=False);\n",
    "\n",
    "plt.title('US Daily New Cases Last 90 Days',fontsize=20)\n",
    "plt.savefig(f'./covid_data_update/us_{snames}_last_90_days_{day}.png');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Daily New Cases in tabular format\n",
    "pd.set_option('display.max_rows', 300)\n",
    "pd.set_option('display.min_rows', 300)\n",
    "state.sort_index(ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom country dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#list(scd.all_countries.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creates a custom country dict\n",
    "c_string = input('Enter country codes seperated by a space:') or 'fr it es'\n",
    "clist = scd.custom_list (c_string)\n",
    "\n",
    "country_dict = {key: value for key, value in scd.all_countries.items() if value in clist}\n",
    "print(country_dict)\n",
    "\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scraping section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_list = list(country_dict.values())\n",
    "c_list\n",
    "\n",
    "# create an empty pandas df with column headers from country_dict, using the starting dates for the country as index\n",
    "country = pd.DataFrame(columns = c_list,index=c_index)\n",
    "country.sort_index(ascending = False).head()\n",
    "\n",
    "base_url='https://www.worldometers.info/coronavirus/country/'\n",
    "# Here the keys are the country names and the values are the 2-letter abbreviation\n",
    "for key, value in country_dict.items():\n",
    "    url = base_url+key\n",
    "    print(url)\n",
    "\n",
    "    # scrape web page for country info and assign to soup\n",
    "    response = requests.get(url)\n",
    "    #response.status_code\n",
    "    page = response.text\n",
    "    #print(response.text[:400])\n",
    "    soup = bs(page)\n",
    "    \n",
    "    # Find block of text/data near 'graph-cases-daily' \n",
    "    re_graph = re.compile('graph-cases')\n",
    "    dat = soup.find(text=re_graph)\n",
    "   \n",
    "    try:\n",
    "        data = soup.find(text=re_graph).parent\n",
    "    except:\n",
    "        print(f'Unable to find {url}')\n",
    "        print()\n",
    "        break\n",
    "\n",
    "    # Regex to pull out data chunk out of the larger soup like data\n",
    "    myregex = re.compile (r'data:.*\\]')\n",
    "    mo = myregex.search(str(data))\n",
    "\n",
    "    #mo.group() is a string so easy to get rid of the first entry\n",
    "    country_previous_cases = mo.group().split(',')[1:]\n",
    "    #print(country_previous_cases)\n",
    "    previous_cases = [\"0\" if i == 'null' else i for i in country_previous_cases]\n",
    "    \n",
    "    len(previous_cases)\n",
    "\n",
    "    # merge countries into the existing df and apply the function clean_up to convert strings to ints\n",
    "    country[value] = previous_cases\n",
    "    country[value] = country[value].fillna(0).apply(clean_up)\n",
    "    \n",
    "    time.sleep(2)\n",
    "country.clip(lower=0,inplace=True) #large negative number removed for better graphic clarity\n",
    "country.sort_index(ascending = False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a reveresed iso3166 country-code dictionary\n",
    "iso3166r = scd.reverse_dict(scd.iso3166)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "country_dict = {key: value for key, value in scd.iso3166r.items() if value in clist}\n",
    "w_cols = list(country_dict.keys())\n",
    "\n",
    "# fix uk entries to match conventional country names\n",
    "if 'uk' in w_cols:\n",
    "    w_cols.remove('uk')\n",
    "    w_cols.append('United Kingdom')\n",
    "if 'US' in w_cols:\n",
    "    w_cols.remove('US')\n",
    "    w_cols.append('United States')\n",
    "w_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract just the populations for the states of interest\n",
    "wpop_series = world_pop.loc[w_cols].pop_millions\n",
    "wpop_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wpop_series.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wpop_series.rename(index=iso3166r, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wpop_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# repair issues with uk and us\n",
    "wpop_series.rename({'United Kingdom':'UK','United States':'US'},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "world_cases_by_million = (country/wpop_series).round()\n",
    "world_cases_by_million.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot 7-day moving averge per million population\n",
    "plt.close('all')\n",
    "fig,ax = plt.subplots(1,1,figsize=(18,8))\n",
    "roll_data_all = world_cases_by_million.rolling(window=7).mean()\n",
    "roll_data_all.plot(ax=ax, linewidth=3);\n",
    "plt.title('World-Seven-day rolling averges per million population',fontsize=20);\n",
    "#plt.savefig(f'./covid_data_update/us_rolling_avg_per_million_{day}.png');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Allows user to select the country for the rolling average\n",
    "c_available = list(country.columns)\n",
    "print(f'Countries available: {c_available}')\n",
    "print()\n",
    "\n",
    "snames = (list2string(c_available))\n",
    "\n",
    "select_country = input('Choose country for rolling averge:') or c_available[0]\n",
    "select_country = select_country.upper()\n",
    "\n",
    "if select_country not in c_available:\n",
    "    select_country = c_available[0]\n",
    "\n",
    "# Plot Daily New Cases and 7-day moving averge\n",
    "fig,ax = plt.subplots(1,1,figsize=(18,8))\n",
    "roll_data = country.loc[:,[select_country]].rolling(window=7).mean()\n",
    "\n",
    "\n",
    "roll_data.plot(ax=ax, linewidth=3, color='r')\n",
    "country.plot(kind='area',alpha=.4,ax=ax,stacked=False)\n",
    "plt.title('World Daily New Cases and 7-day moving average in RED',fontsize=20);\n",
    "# insert {snames} if desired \n",
    "plt.savefig(f'./covid_data_update/world_{day}.png');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot 7-day moving averge\n",
    "plt.close('all')\n",
    "fig,ax = plt.subplots(1,1,figsize=(18,8))\n",
    "roll_data_all = country.rolling(window=7).mean()\n",
    "roll_data_all.plot(ax=ax, linewidth=3);\n",
    "plt.title('World-Seven-day rolling averges',fontsize=20)\n",
    "# insert {snames} if desired \n",
    "plt.savefig(f'./covid_data_update/world_rolling_avg_{day}.png');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot last 60 days\n",
    "plt.close('all')\n",
    "# Select last 60 days only\n",
    "country_last60 = country.tail(60)\n",
    "\n",
    "roll_data = country_last60.loc[:,[select_country]].rolling(window=7).mean()\n",
    "fig,ax = plt.subplots(1,1,figsize=(16,8))\n",
    "roll_data.plot(ax=ax, linewidth=3, color='r')\n",
    "country_last60.plot(kind='area',alpha=.2,ax=ax,stacked=False);\n",
    "\n",
    "plt.title('World Daily New Cases Last 60 Days',fontsize=20)\n",
    "plt.savefig(f'./covid_data_update/world_{snames}_last_60_days_{day}.png');\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot last 90 days\n",
    "plt.close('all')\n",
    "# Select last 90 days only\n",
    "country_last90 = country.tail(90)\n",
    "\n",
    "roll_data = country_last90.loc[:,[select_country]].rolling(window=7).mean()\n",
    "fig,ax = plt.subplots(1,1,figsize=(16,8))\n",
    "roll_data.plot(ax=ax, linewidth=3, color='r')\n",
    "country_last90.plot(kind='area',alpha=.2,ax=ax,stacked=False);\n",
    "\n",
    "plt.title('World Daily New Cases Last 90 Days',fontsize=20)\n",
    "plt.savefig(f'./covid_data_update/world_{snames}_last_90_days_{day}.png');\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Daily New Cases in tabular format\n",
    "pd.set_option('display.max_rows', 300)\n",
    "pd.set_option('display.min_rows', 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Note that new cases provided for Spain have a pattern of muliple days with exactly the same number\n",
    "country.sort_index(ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save merged dataframes to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge state and country dfs into one\n",
    "world = state.merge(country,left_index=True,right_index=True,how='outer')\n",
    "world = world.fillna(0).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sorting the table with recent dates on the top\n",
    "world_table = world.sort_index(ascending = False)\n",
    "\n",
    "# Save to csv by uncommenting out the next line\n",
    "# world_table.to_csv(f'./covid_data/world_table{day}.csv')\n",
    "world_table.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_by_million = state_cases_by_million.merge(world_cases_by_million,left_index=True, right_index=True, how='outer')\n",
    "total_by_million.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weekly Sums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note that the last week may be only a partial unless this is executed at end of week\n",
    "# End of week is Sunday, so this should be executed on Mondays\n",
    "df1 = world.resample('w').sum()\n",
    "df1.sort_index(ascending = False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom graphs section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "world.tail()\n",
    "total_by_million.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import date_select as ds\n",
    "start,stop = ds.date_maker()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "world_cols = world.columns.to_list()\n",
    "print (world_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select custom states and countries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_string = input('Enter any codes from the above list:') or world_cols\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slist = scd.custom_list (s_string)\n",
    "\n",
    "new_slist =[]\n",
    "for item in slist:\n",
    "    if item in world_cols:\n",
    "        new_slist.append(item)\n",
    "new_slist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = world.loc[start:stop, new_slist]\n",
    "title ='Custom rolling averges'\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = total_by_million.loc[start:stop, new_slist]\n",
    "title1 ='Custom rolling averges by million'\n",
    "df1.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot custom moving averge (default: 7 days) \n",
    "plt.close('all')\n",
    "fig,ax = plt.subplots(1,1,figsize=(18,8))\n",
    "roll_data_all = df.rolling(window=7).mean()\n",
    "roll_data_all.plot(ax=ax, linewidth=3);\n",
    "plt.title(title,fontsize=20);\n",
    "#plt.savefig(f'./covid_data_update/us_rolling_avg_per_million_{day}.png');\n",
    "\n",
    "# Plot custom moving averge (default: 7 days) per million population\n",
    "fig,ax = plt.subplots(1,1,figsize=(18,8))\n",
    "roll_data_all = df1.rolling(window=7).mean()\n",
    "roll_data_all.plot(ax=ax, linewidth=3);\n",
    "plt.title(title1,fontsize=20);\n",
    "#plt.savefig(f'./covid_data_update/us_rolling_avg_per_million_{day}.png');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Displays all updated graphs files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls covid_data_update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "commented out this cell - redundancy of displaying plots twice\n",
    "\n",
    "!ls covid_data_update/*.png > flist_of_covid_png \n",
    "\n",
    "# Loop through the file flist and store filenames in png_list\n",
    "with open('flist_of_covid_png') as f:\n",
    "    png_str = f.read()\n",
    "png_list = png_str.split('\\n')[0:-1]\n",
    "\n",
    "png_list\n",
    "\n",
    "from IPython.display import Image\n",
    "\n",
    "for file in png_list:    \n",
    "    local = Image(file)\n",
    "    local\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tabla rasa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this cell will delete all files created in todays session\n",
    "!rm -rf covid_data_update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure helper files used have been removed\n",
    "!rm -f covid_data/covid_text covid_data/flist_of_covid_png covid_data/temp.xlsx\n",
    "!rm -f flist_of_covid_png"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "If todays files are not deleted, they will automatically be backed up to the covid_data directory, the next time this program is run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "PyCon2020_Scraping_Wikipedia.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
